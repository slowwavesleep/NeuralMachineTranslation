### Baseline
```
model = BasicEncoderDecoder(vocab_size=VOCAB_SIZE,
                            emb_dim=256,
                            model_dim=256,
                            model_layers=2,
                            model_dropout=0.3,
                            padding_index=PAD_INDEX)
```

### Подбор датасета
Начал с подготовки пайплайна для всего процесса обучения. Использовал датасет субтитров выступлений TED для перевода
с русского на французский (ссылка). Оказалось, что там плохой перевод и плохое выравнивание. Использовать такой датасет
нецелесообразно.


Затем тестировал датасет с переводами с русского на английский (ссылка). Это довольнно качественный датасет, но там
не было метрик, с которыми можно было бы сравнить качество получившейся модели.

В итоге остановился на русско-укранском датасете, предлагаемом Helsinki NLP (ссылка). Помимо непосредственно метрик
для данного датасета, также предлаются и тестовые данные, на которых можно посчитать свои метрики и сравнить.