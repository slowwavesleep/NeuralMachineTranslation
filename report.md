## Отчет

### Описание задачи
Задачей данного проекта является автоматический перевод с русского на украинский.

Цель — приблизится по адекватности перевода иметрике BLEU к существующей модели (трансформеру).

#### Входные данные
Набор примеров, предварительно разбитый на train, dev, test части. Каждый файл на каждой строке содержит пример на
одном языке. Некоторые примеры достаточно странные. Например, куски предложений без начала или конца. Дополнительную 
предобработку не проводил. Для токенизации использовал `YouTokenToMe`.

#### Формат выходных данных

*оригинал*


*эталонный перевод*


*перевод модели*

### Обработка данных

### Немного о машинном переводе


### Подбор датасета
Начал с подготовки пайплайна для всего процесса обучения. Использовал 
[датасет субтитров](https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus) выступлений TED для перевода
с русского на французский. К сожалению, выяснилось, что в данном датасете довольно плохой перевод. Кроме того, он 
выровнен неправильно, т.е. пары предложений могут сильно отличаться по содержанию.

Затем тестировал [датасет](https://www.manythings.org/anki/) с переводами с русского на английский. Этот датасет, как
мне показалось, более качественный. Таких явных ошибок, как в предыдущем, я не заметил, но они, очевидно, есть. Также,
как и [предупреждают](https://www.manythings.org/corpus/warningtatoeba.html), некоторые предложения довольно
неестественны.

В итоге остановился на [русско-укранском датасете](https://object.pouta.csc.fi/Tatoeba-Challenge/rus-ukr.tar),
входящим в [Tatoeba Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge), предлагаемом Helsinki NLP.
Основными критериями выбора были: наличие достаточно большого числа примеров, наличие тестовых данных и посчитанной
на них метрики BLEU, а также наличие возможности самостоятельно оценить адекватность перевода.

### Подсчет метрики
Добавление gradient clipping

1.8 -> 2.1

31.09 -> 31.27 -> 32.98

### Baseline
Для того, чтобы протестировать построенный пайплайн и оценить минимальный порог качества, использовал простую Encoder
Decoder модель, состоящую из двух LSTM.
Параметры, использованные при обучении модели:


- Размерность эмбеддингов — 256
- Размерность LSTM — 1000
- Spatial Dropout в обеих LSTM — 0.3
- Количество эпох — 5
- Размер батча — 512
- Максимальная длина для обоих языков — 20
- Размер словаря для обоих языков — 7000
- Количество примеров для обучения — 100000

Данная модель показала достаточно низкое качество — 1.8 BLEU. При просмотре самих переводов это, конечно, тоже очевидно.
Во многих случаях перевод вообще никак не связан с входным предложением.

```
Спасибо!
Дякую!
[ Примітка]
```






