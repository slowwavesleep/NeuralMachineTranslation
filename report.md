## Отчет

### Описание задачи
Задачей данного проекта является автоматический перевод с русского на украинский.

Цель — приблизится по адекватности перевода и значению метрики BLEU к существующей модели (трансформеру), 
[равной **64**](https://github.com/Helsinki-NLP/Tatoeba-Challenge/tree/master/models/rus-ukr).

#### Входные данные
Набор примеров, предварительно разбитый на train, dev, test части. Каждый файл на каждой строке содержит пример на
одном языке. Некоторые примеры достаточно странные. Например, куски предложений без начала или конца. Дополнительную 
предобработку не проводил. Для токенизации использовал `YouTokenToMe`.

#### Формат выходных данных
Для корректного подсчета метрики используется следующий формат записи переводов тестовых примеров, сделанных моделью.

- *<оригинал>*
- *<эталонный перевод>*
- *<перевод модели>*
- *<пустая строка>*

### Обработка данных
Данные Tatoeba Challenge не потребовалось отдельно обрабатывать. Но, поскольку я сначала тестировал другие датасеты,
пришлось подготовить некоторые утилиты для чтения, преобразования в нужный формат и разбиения на train, test, dev.

При необходимости их можно использовать для каких-то других данных.

Какой-либо фильтрации симоволов или приведения к одному регистру не делал ни для одного из датасетов и, как оказалось,
это не так уж сильно на что-то влияет.

### Немного о машинном переводе
Вообще машинный перевод — это по сути самая первая задача компьютерной лингвистики. Первая система машинного перевода
была представлена еще в 1954 году в ходе Джорджтаунского эксперимента. Система переводила предложения с русского на
английский. Она работала на правилах и ограничивалась узкой предметной областью.


Затем появились системы, основанные на примерах. Из которых развились и системы нейросетевого машинного перевода.


### Подбор датасета
Начал с подготовки пайплайна для всего процесса обучения. Использовал 
[датасет субтитров](https://github.com/ajinkyakulkarni14/TED-Multilingual-Parallel-Corpus) выступлений TED для перевода
с русского на французский. К сожалению, выяснилось, что в данном датасете довольно плохой перевод. Кроме того, он 
выровнен неправильно, т.е. пары предложений могут сильно отличаться по содержанию.

Затем тестировал [датасет](https://www.manythings.org/anki/) с переводами с русского на английский. Этот датасет, как
мне показалось, более качественный. Таких явных ошибок, как в предыдущем, я не заметил, но они, очевидно, есть. Также,
как и [предупреждают](https://www.manythings.org/corpus/warningtatoeba.html), некоторые предложения довольно
неестественны.

В итоге остановился на [русско-украинском датасете](https://object.pouta.csc.fi/Tatoeba-Challenge/rus-ukr.tar),
входящим в [Tatoeba Challenge](https://github.com/Helsinki-NLP/Tatoeba-Challenge), предлагаемом Helsinki NLP.
Основными критериями выбора были: наличие достаточно большого числа примеров, наличие тестовых данных и посчитанной
на них метрики BLEU, а также наличие возможности самостоятельно оценить адекватность перевода.

### Процесс обучения

Подход к созданию модели был такой. Сначала я сделал бейзлайн модель и посчитатал на ней метрику BLEU.
Затем я стал её последовательно усложнять.


Заметно на качество модели повлияло следующее:
- Использование механизма attention
- Использование двунаправленной LSTM в декодере
- Добавление pack padded sequence в энкодере и декодере
- Добавление gradient clipping

Сложно оценить влияние по метрикам:
- Добавление дропаута
- Добавление layer norm
- Добавление функции активации
- Маскирование падов в attention

### Подсчет метрики

Метрика BLEU призвана оценивать качество машшинного перевода.

### Baseline
Для того, чтобы протестировать построенный пайплайн и оценить минимальный порог качества, использовал простую Encoder
Decoder модель, состоящую из двух LSTM.
Параметры, использованные при обучении модели:


- Размерность эмбеддингов — 256
- Размерность LSTM — 1000
- Spatial Dropout в обеих LSTM — 0.3
- Количество эпох — 5
- Размер батча — 512
- Максимальная длина для обоих языков — 20
- Размер словаря для обоих языков — 7000
- Количество примеров для обучения — 100000

Данная модель показала достаточно низкое качество — 2.1 BLEU. При просмотре самих переводов это, конечно, тоже очевидно.
Во многих случаях перевод вообще никак не связан с входным предложением по содержанию.

*Пример 1*
```
Твой дом большой.
Твій будинок великий.
Температор!
```
*Пример 2*
```
Я боюсь грозы.
Я боюся грози.
Я просто...
```







